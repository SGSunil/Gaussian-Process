{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process\n",
    "\n",
    "In this notebook, we will implement a Gaussian Process model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from pyDOE import lhs\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x):\n",
    "    \"\"\"1D Test Function\"\"\"\n",
    "    \n",
    "    y = (x*6-2)**2*np.sin(x*12-4)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianProcess:\n",
    "    \"\"\"A Gaussian Process class that trains and predicts \n",
    "    with a Gaussian Process model\"\"\"\n",
    "    \n",
    "    def __init__(self, n_restarts, optimizer, bounds):\n",
    "        \"\"\"Initialize a Gaussian Process model\n",
    "        \n",
    "        Input\n",
    "        ------\n",
    "        n_restarts: number of restarts of the local optimizer\n",
    "        optimizer: algorithm of local optimization\n",
    "        bounds: Bounds for GP model parameter theta\"\"\"\n",
    "        \n",
    "        self.n_restarts = n_restarts\n",
    "        self.optimizer = optimizer\n",
    "        self.bounds = bounds\n",
    "        \n",
    "    def likelihood(self, theta):\n",
    "        \"\"\"Likelihood function\"\"\"\n",
    "        \n",
    "        theta = 10**theta    # Correlation length\n",
    "        n = self.X.shape[0]       # Number of training instances\n",
    "        one = np.ones((n,1))      # A vector of ones\n",
    "        \n",
    "        # Construct correlation matrix\n",
    "        Psi = np.zeros((n,n))\n",
    "        for i in range(n-1):\n",
    "            for j in range(i+1,n):\n",
    "                Psi[i,j] = np.exp(-np.sum(theta*(self.X[i,:]-self.X[j,:])**2))\n",
    "        Psi = Psi + Psi.T + np.eye(n) + np.eye(n)*1e-10\n",
    "        \n",
    "        # Mean estimation\n",
    "        mu = (one.T @ np.linalg.inv(Psi) @ self.y)/ (one.T @ np.linalg.inv(Psi) @ one)\n",
    "        \n",
    "        # Variance estimation\n",
    "        SigmaSqr = (self.y-mu*one).T @ np.linalg.inv(Psi) @ (self.y-mu*one) / n\n",
    "        \n",
    "        # Compute log-likelihood\n",
    "        DetPsi = np.linalg.det(Psi)\n",
    "        LnLike = -(n/2)*np.log(SigmaSqr) - 0.5*np.log(DetPsi)\n",
    "        \n",
    "        # Update attributes\n",
    "        self.Psi, self.mu, self.SigmaSqr = Psi, mu, SigmaSqr\n",
    "        \n",
    "        return -LnLike.flatten()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"GP model training\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X: 2D array of shape (n_samples, n_features)\n",
    "        y: 2D array of shape (n_samples, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "        # Generate random starting points (Latin Hypercube)\n",
    "        lhd = lhs(self.X.shape[1], samples=self.n_restarts)\n",
    "        # Scale random samples to the given bounds \n",
    "        lb, ub = self.bounds[0], self.bounds[1]\n",
    "        initial_points = (ub-lb)*lhd + lb\n",
    "        \n",
    "        # Create A Bounds instance for optimization\n",
    "        bnds = Bounds(lb,ub)\n",
    "        \n",
    "        # Run local optimizer on all points\n",
    "        self.opt_para, self.opt_func = np.zeros(self.n_restarts), np.zeros(self.n_restarts)\n",
    "        for i,point in enumerate(initial_points):\n",
    "            res = minimize(self.likelihood, point, method=self.optimizer,\n",
    "                bounds=bnds)\n",
    "            self.opt_para[i] = res.x\n",
    "            self.opt_func[i] = res.fun\n",
    "        \n",
    "        # Locate the optimum results\n",
    "        self.theta = self.opt_para[np.argmin(self.opt_func)]\n",
    "        \n",
    "        # Update GP attributes\n",
    "        self.LnLike = -self.likelihood(self.theta)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"GP model predicting\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X_test: Prediction sites\"\"\"\n",
    "        \n",
    "        theta = 10**self.theta\n",
    "        n = self.X.shape[0]\n",
    "        one = np.ones((n,1))\n",
    "        \n",
    "        # Construct correlation matrix between test and train data\n",
    "        psi=np.zeros((n,X_test.shape[0]))\n",
    "        for i in range(n):\n",
    "            for j in range(X_test.shape[0]):\n",
    "                psi[i,j] = np.exp(-np.sum(theta*(self.X[i,:]-X_test[j,:])**2))\n",
    "        \n",
    "        # Mean prediction\n",
    "        f = self.mu + psi.T @ np.linalg.inv(self.Psi) @ (self.y-self.mu*one)\n",
    "        \n",
    "        # Variance prediction\n",
    "        SSqr = self.SigmaSqr*(1 - psi.T @ np.linalg.inv(self.Psi) @ psi)\n",
    "        \n",
    "        return f, SSqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0.0, 0.1, 0.2, 0.4, 0.6, 1], ndmin=2).T\n",
    "y_train = test_function(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP = GaussianProcess(n_restarts=30, optimizer='L-BFGS-B', bounds=(-3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[0.5],[0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0029982 ]\n",
      " [-0.65657677]]\n",
      "[[5.49644536e-01 3.95380955e+01]\n",
      " [3.95380955e+01 4.43427610e-09]]\n"
     ]
    }
   ],
   "source": [
    "f, SSqr = GP.predict(X_test)\n",
    "print(f)\n",
    "print(SSqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90929743],\n",
       "       [-0.65657677]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
